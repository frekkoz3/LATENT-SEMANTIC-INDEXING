{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "duq4gOzIpp7F"
   },
   "source": [
    "# A Simple Boolean Retrieval System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MnJXnmpdpp7J"
   },
   "outputs": [],
   "source": [
    "from functools import total_ordering, reduce  \n",
    "import csv  # Import the csv module for CSV file parsing\n",
    "import re  # Import the re module for regular expression operations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ty7C6ESQpp7L"
   },
   "source": [
    "### Postings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qBhikJmwpp7L"
   },
   "outputs": [],
   "source": [
    "@total_ordering  # This decorator will add all rich comparison methods based on the definitions of __eq__ and __gt__.\n",
    "class Posting:    # The class represents a 'Posting' in an index \n",
    "    \n",
    "    def __init__(self, docID):\n",
    "        # The initializer method for the class, which takes a document ID as an argument.\n",
    "        self._docID = docID  # The document ID is stored in a protected member variable.\n",
    "        \n",
    "    def get_from_corpus(self, corpus):\n",
    "        # A method to retrieve a document's contents from a corpus using the stored document ID.\n",
    "        return corpus[self._docID]  # Returns the document associated with the document ID from the corpus.\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        # Special method to check equality with another Posting, based on document ID.\n",
    "        return self._docID == other._docID  # Returns True if the document IDs are equal, otherwise False.\n",
    "    \n",
    "    def __gt__(self, other):\n",
    "        # Special method to check if this Posting is greater than another Posting, based on document ID.\n",
    "        return self._docID > other._docID  # Returns True if this document ID is greater than the other's.\n",
    "    \n",
    "    def __repr__(self):\n",
    "        # Special method to provide the official string representation of the Posting.\n",
    "        return str(self._docID)  # Returns the string form of the document ID.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Posting(\"123\")<Posting(\"3333\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lLw9bNHLpp7M"
   },
   "source": [
    "### Posting Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "u81tZ4y3pp7M"
   },
   "outputs": [],
   "source": [
    "class PostingList:\n",
    "    # This class represents a collection  of postings\n",
    "    \n",
    "    def __init__(self):\n",
    "        # The initializer method for the class. It initializes an empty list of postings.\n",
    "        self._postings = []  # Protected member variable that holds the list of postings.\n",
    "\n",
    "    @classmethod\n",
    "    def from_docID(cls, docID):\n",
    "        # A class method to create a PostingList instance with a single Posting from a document ID.\n",
    "        plist = cls()  # Creates a new instance of the class.\n",
    "        plist._postings = [(Posting(docID))]  # Initializes the postings list with a single Posting.\n",
    "        return plist  # Returns the newly created PostingList instance.\n",
    "    \n",
    "    @classmethod\n",
    "    def from_posting_list(cls, postingList):\n",
    "        # A class method to create a PostingList instance from an existing list of Postings.\n",
    "        plist = cls()  # Creates a new instance of the class.\n",
    "        plist._postings = postingList  # Sets the postings list to the provided list.\n",
    "        return plist  # Returns the newly created PostingList instance.\n",
    "\n",
    "    def merge(self, other):\n",
    "        # A method to merge another PostingList into this one, avoiding duplicates.\n",
    "        i = 0  # Start index for the other PostingList.\n",
    "        last = self._postings[-1]  # The last Posting in the current list.\n",
    "        # Loop through the other PostingList and skip duplicates.\n",
    "        while (i < len(other._postings) and last == other._postings[i]):\n",
    "            i += 1  # Increment the index if a duplicate is found.\n",
    "        self._postings += other._postings[i:]  # Append the non-duplicate postings from the other list.\n",
    "    \n",
    "    def intersection(self, other):\n",
    "        # A method to compute the intersection of this PostingList with another.\n",
    "        intersection = []  # Start with an empty list for the intersection.\n",
    "        i = 0  # Index for this PostingList.\n",
    "        j = 0  # Index for the other PostingList.\n",
    "        # Loop until one of the lists is exhausted.\n",
    "        while (i < len(self._postings) and j < len(other._postings)):\n",
    "            # If both postings are equal, add to the intersection.\n",
    "            if (self._postings[i] == other._postings[j]):\n",
    "                intersection.append(self._postings[i]) \n",
    "                i += 1\n",
    "                j += 1\n",
    "            # If the current posting is less, increment this list's index.\n",
    "            elif (self._postings[i] < other._postings[j]):\n",
    "                i += 1\n",
    "            # If the other posting is less, increment the other list's index.\n",
    "            else:\n",
    "                j += 1\n",
    "        return PostingList.from_posting_list(intersection)  # Return a new PostingList of the intersection.\n",
    "\n",
    "\n",
    "\n",
    "    def union(self, other):\n",
    "        # A method to compute the union of this PostingList with another.\n",
    "        union = []  # Start with an empty list for the union.\n",
    "        i = 0  # Index for this PostingList.\n",
    "        j = 0  # Index for the other PostingList.\n",
    "        # Loop until one of the lists is exhausted.\n",
    "        while (i < len(self._postings) and j < len(other._postings)):\n",
    "            # If both postings are equal, add to the union and increment both indexes.\n",
    "            if (self._postings[i] == other._postings[j]):\n",
    "                union.append(self._postings[i])\n",
    "                i += 1\n",
    "                j += 1\n",
    "            # If the current posting is less, add it to the union and increment this list's index.\n",
    "            elif (self._postings[i] < other._postings[j]):\n",
    "                union.append(self._postings[i])\n",
    "                i += 1\n",
    "            # Otherwise, add the other posting to the union and increment the other list's index.\n",
    "            else:\n",
    "                union.append(other._postings[j])\n",
    "                j += 1\n",
    "        # Add any remaining postings from both lists to the union.\n",
    "        for k in range(i, len(self._postings)):\n",
    "            union.append(self._postings[k])\n",
    "        for k in range(j, len(other._postings)):\n",
    "            union.append(other._postings[k])\n",
    "        return PostingList.from_posting_list(union)  # Return a new PostingList of the union.\n",
    "    \n",
    "    \n",
    "    def get_from_corpus(self, corpus):\n",
    "        # A method to retrieve the contents of each Posting from a corpus.\n",
    "        return list(map(lambda x: x.get_from_corpus(corpus), self._postings))  # Use map to apply the retrieval to each Posting.\n",
    "    \n",
    "    def __repr__(self):\n",
    "        # Special method to provide the official string representation of the PostingList.\n",
    "        return \", \".join(map(str, self._postings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5wU2rlGXpp7N"
   },
   "source": [
    "### Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom exception class for handling errors specific to merge operations.\n",
    "class ImpossibleMergeError(Exception):\n",
    "    pass\n",
    "\n",
    "# The total_ordering decorator will automatically provide the other comparison methods based on __eq__ and __gt__.\n",
    "@total_ordering\n",
    "class Term:\n",
    "    # A class that represents a term in a document, along with its posting list.\n",
    "\n",
    "    def __init__(self, term, docID):\n",
    "        # The initializer method for the class, taking a term and a document ID as arguments.\n",
    "        self.term = term  # Public attribute to store the term.\n",
    "        # Initialize posting_list for the term with a PostingList created from the given document ID.\n",
    "        self.posting_list = PostingList.from_docID(docID)\n",
    "        \n",
    "    def merge(self, other):\n",
    "        # A method to merge another Term's posting list into this one if they have the same term.\n",
    "        if (self.term == other.term):\n",
    "            # If terms match, merge the posting lists.\n",
    "            self.posting_list.merge(other.posting_list)\n",
    "        else:\n",
    "            # If terms don't match, it's not possible to merge, so raise an exception.\n",
    "            raise ImpossibleMergeError\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        # Special method to check equality with another Term based on the term string.\n",
    "        return self.term == other.term  # Comparison is done lexicographically.\n",
    "    \n",
    "    def __gt__(self, other):\n",
    "        # Special method to determine if this Term is greater than another, based on the term string.\n",
    "        return self.term > other.term  # Comparison is done lexicographically.\n",
    "    \n",
    "    def __repr__(self):\n",
    "        # Special method to provide the official string representation of the Term.\n",
    "        return self.term + \": \" + repr(self.posting_list)  # Concatenate the term and its posting list's string representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T-_DNEW8pp7P"
   },
   "source": [
    "### Inverted Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to normalize text by removing punctuation, converting to lowercase.\n",
    "def normalize(text):\n",
    "    # Removes punctuation from the text using a regular expression.\n",
    "    no_punctuation = re.sub(r'[^\\w\\s^-]', '', text)\n",
    "    # Converts the text to lowercase.\n",
    "    downcase = no_punctuation.lower()\n",
    "    # Returns the normalized text.\n",
    "    return downcase\n",
    "\n",
    "# Function to tokenize the description of a movie into individual words.\n",
    "def tokenize(movie):\n",
    "    # Normalize the movie description.\n",
    "    text = normalize(movie.description)\n",
    "    # Split the text into a list of tokens (words) and return it.\n",
    "    return list(text.split())\n",
    "\n",
    "# Define a class that represents an inverted index.\n",
    "class InvertedIndex:\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Initialize the inverted index with an empty dictionary.\n",
    "        self._dictionary = []\n",
    "        \n",
    "    # Class method to create an inverted index from a corpus of documents.\n",
    "    @classmethod\n",
    "    def from_corpus(cls, corpus):\n",
    "        # Create an intermediate dictionary to store terms and their postings.\n",
    "        intermediate_dict = {}\n",
    "        # Iterate over the documents in the corpus.\n",
    "        for docID, document in enumerate(corpus):\n",
    "            # Tokenize the document into individual words.\n",
    "            tokens = tokenize(document) \n",
    "            for token in tokens:   ## Hello in document 37\n",
    "                # Create a new term with the token and the current document ID.\n",
    "                term = Term(token, docID) ## Helly -> 37\n",
    "                try:\n",
    "                    # Try to merge the term with existing one in the intermediate dictionary.\n",
    "                    intermediate_dict[token].merge(term)\n",
    "                except KeyError:\n",
    "                    # If the term is not already in the dictionary, add it.\n",
    "                    intermediate_dict[token] = term\n",
    "            # Print progress for every 1000 documents processed.\n",
    "            if (docID % 1000 == 0):\n",
    "                print(\"ID: \" + str(docID))\n",
    "        # Create a new InvertedIndex instance.\n",
    "        idx = cls()\n",
    "        # Sort the terms in the intermediate dictionary and store them in the index's dictionary.\n",
    "        idx._dictionary = sorted(intermediate_dict.values(), key=lambda term: term.term)\n",
    "        # Return the newly created inverted index.\n",
    "        return idx\n",
    "    \n",
    "    # Special method to retrieve the posting list for a given term.\n",
    "    def __getitem__(self, key):\n",
    "        # Iterate over the terms in the dictionary.\n",
    "        for term in self._dictionary:\n",
    "            # If the term matches the key, return its posting list.\n",
    "            if term.term == key:\n",
    "                return term.posting_list\n",
    "        # If the term is not found, raise a KeyError.\n",
    "        raise KeyError\n",
    "    \n",
    "    # Special method to provide a string representation of the inverted index.\n",
    "    def __repr__(self):\n",
    "        # Returns a string indicating the number of terms in the dictionary.\n",
    "        return \"A dictionary with \" + str(len(self._dictionary)) + \" terms\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9V_-ECH8pp7Q"
   },
   "source": [
    "### Reading the Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class to hold the title and description of a movie.\n",
    "class MovieDescription:\n",
    "    \n",
    "    def __init__(self, title, description):\n",
    "        # Constructor for the class that initializes the title and description attributes.\n",
    "        self.title = title\n",
    "        self.description = description\n",
    "        \n",
    "    def __repr__(self):\n",
    "        # Special method to provide the string representation of the MovieDescription object.\n",
    "        # It returns the movie's title when the object is printed or shown in the interpreter.\n",
    "        return self.title\n",
    "    \n",
    "# Define a function to read movie descriptions and titles from files.\n",
    "def read_movie_descriptions(filename, movie_names_file ):\n",
    "    # Names of the files containing plot summaries and metadata respectively.\n",
    "    filename = filename\n",
    "    movie_names_file = movie_names_file\n",
    "    \n",
    "    # Open the movie metadata file and read it line by line.\n",
    "    with open(movie_names_file, 'r', encoding=\"utf8\") as csv_file:\n",
    "        # Create a csv.reader object to read the file with tab as the delimiter.\n",
    "        movie_names = csv.reader(csv_file, delimiter='\\t')\n",
    "        # Initialize a dictionary to hold movie IDs and their corresponding titles.\n",
    "        names_table = {}\n",
    "        for name in movie_names:\n",
    "            # Populate the dictionary with movie ID as key and title as value.\n",
    "            names_table[name[0]] = name[2]\n",
    "    \n",
    "    # Open the file containing plot summaries and read it line by line.\n",
    "    with open(filename, 'r', encoding=\"utf8\") as csv_file:\n",
    "        # Create a csv.reader object to read the file with tab as the delimiter.\n",
    "        descriptions = csv.reader(csv_file, delimiter='\\t')\n",
    "        # Initialize a list to hold the corpus of movie descriptions.\n",
    "        corpus = []\n",
    "        for desc in descriptions:\n",
    "            try:\n",
    "                # Create a MovieDescription object using the title from names_table and the description from the file.\n",
    "                movie = MovieDescription(names_table[desc[0]], desc[1])\n",
    "                # Add the MovieDescription object to the corpus.\n",
    "                corpus.append(movie)\n",
    "            except KeyError:\n",
    "                # If the movie ID is not found in names_table, ignore this description.\n",
    "                pass\n",
    "        # Return the populated list of MovieDescription objects.\n",
    "        return corpus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XWuqzHRTpp7R"
   },
   "source": [
    "### Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class for an Information Retrieval (IR) system.\n",
    "class IRsystem:\n",
    "    \n",
    "    def __init__(self, corpus, index):\n",
    "        # Initialize the IR system with a corpus (collection of documents) and the inverted index.\n",
    "        self._corpus = corpus  # The corpus of documents.\n",
    "        self._index = index  # The inverted index for the corpus.\n",
    "        \n",
    "    @classmethod\n",
    "    def from_corpus(cls, corpus):\n",
    "        # Class method to create an IR system instance from a given corpus.\n",
    "        # It creates an inverted index from the corpus first.\n",
    "        index = InvertedIndex.from_corpus(corpus)\n",
    "        # Returns an instance of the IR system with the given corpus and created index.\n",
    "        return cls(corpus, index)\n",
    "    \n",
    "    # Method to answer a query given a list of words.\n",
    "    def answer_query(self, words):         ## ['cat', 'batman']\n",
    "        # Normalize the words in the query to match the normalized index terms.\n",
    "        norm_words = map(normalize, words)\n",
    "        # Retrieve the posting lists for each normalized word from the index.\n",
    "        postings = map(lambda w: self._index[w], norm_words)\n",
    "        # Reduce the list of posting lists by intersecting them, leaving only the common documents.\n",
    "        plist = reduce(lambda x, y: x.intersection(y), postings)\n",
    "        # Return the list of documents from the corpus that match all query words.\n",
    "        return plist.get_from_corpus(self._corpus)\n",
    "    \n",
    "# Function to execute a text query against an IR system.\n",
    "def query(ir, text):\n",
    "    # Split the text query into individual words.\n",
    "    words = text.split()\n",
    "    # Get the answer to the query using the IR system's answer_query method.\n",
    "    answer = ir.answer_query(words)\n",
    "    # Print out each movie that matches the query.\n",
    "    for movie in answer:\n",
    "        print(movie)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "51emy_vhpp7T"
   },
   "outputs": [],
   "source": [
    "corpus = read_movie_descriptions(filename = 'data/plot_summaries.txt', movie_names_file = 'data/movie.metadata.tsv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "2zNDrhAipp7S"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 0\n",
      "ID: 1000\n",
      "ID: 2000\n",
      "ID: 3000\n",
      "ID: 4000\n",
      "ID: 5000\n",
      "ID: 6000\n",
      "ID: 7000\n",
      "ID: 8000\n",
      "ID: 9000\n",
      "ID: 10000\n",
      "ID: 11000\n",
      "ID: 12000\n",
      "ID: 13000\n",
      "ID: 14000\n",
      "ID: 15000\n",
      "ID: 16000\n",
      "ID: 17000\n",
      "ID: 18000\n",
      "ID: 19000\n",
      "ID: 20000\n",
      "ID: 21000\n",
      "ID: 22000\n",
      "ID: 23000\n",
      "ID: 24000\n",
      "ID: 25000\n",
      "ID: 26000\n",
      "ID: 27000\n",
      "ID: 28000\n",
      "ID: 29000\n",
      "ID: 30000\n",
      "ID: 31000\n",
      "ID: 32000\n",
      "ID: 33000\n",
      "ID: 34000\n",
      "ID: 35000\n",
      "ID: 36000\n",
      "ID: 37000\n",
      "ID: 38000\n",
      "ID: 39000\n",
      "ID: 40000\n",
      "ID: 41000\n",
      "ID: 42000\n"
     ]
    }
   ],
   "source": [
    "ir = IRsystem.from_corpus(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Star Wars Episode V: The Empire Strikes Back\n",
      "Star Wars Episode II: Attack of the Clones\n",
      "George Lucas in Love\n",
      "Something, Something, Something Dark Side\n",
      "Return of the Ewok\n",
      "Aliens in the Wild, Wild West\n",
      "Star Wars Episode III: Revenge of the Sith\n",
      "Star Wars Episode VI: Return of the Jedi\n",
      "Star Wars: The Clone Wars\n",
      "Gulliver's Travels\n",
      "Lego Star Wars: The Quest for R2-D2\n",
      "It's a Trap!\n",
      "LEGO Star Wars: Revenge of the Brick\n"
     ]
    }
   ],
   "source": [
    "query(ir, \"yoda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "oQWNPt-rpp7T"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Lord of the Rings: The Fellowship of the Ring\n",
      "The Lord of the Rings\n",
      "The Hunt for Gollum\n",
      "The Return of the King\n",
      "Date Movie\n",
      "The Lord of the Rings: The Two Towers\n",
      "The Lord of the Rings: The Return of the King\n"
     ]
    }
   ],
   "source": [
    "query(ir, \"frodo ring\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Lord of the Rings: The Fellowship of the Ring\n",
      "The Lord of the Rings\n",
      "The Hunt for Gollum\n",
      "The Lord of the Rings: The Two Towers\n"
     ]
    }
   ],
   "source": [
    "query(ir, \"frodo ring lord\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "BooleanRetrieval.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
